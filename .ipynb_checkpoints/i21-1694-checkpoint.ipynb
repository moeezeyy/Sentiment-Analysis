{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aamishrafique/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_images = os.getcwd() + '/images'  # path to the image folder\n",
    "# for filename in os.scandir(path_to_images):  # iterating over the images folder\n",
    "#     path = filename.path  # path of image\n",
    "#     image = Image.open(path)  # opening image\n",
    "#     image = image.resize((128, 128))  # resizing image to 128p x 128p\n",
    "#     image = image.convert('RGB')  # converting to color (for black and white images)\n",
    "#     image.save(path)  # saving image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = os.getcwd() + '/images'  # path to the image folder\n",
    "names = []\n",
    "images = []\n",
    "for root, temp, files in os.walk(path_to_images):\n",
    "    for filename in files:\n",
    "        path = root + \"/\" + filename  # path of image\n",
    "        image = imread(path, as_gray=True)  # reading image as gray\n",
    "        image = image.flatten()  # flattening the image\n",
    "        names.append(filename)\n",
    "        images.append(image)\n",
    "\n",
    "names = np.array(names)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.6648502 , 0.5897749 , 0.61048392, ..., 0.16326941, 0.17111255,\n",
       "        0.12797529],\n",
       "       [0.74940039, 0.74940039, 0.74940039, ..., 0.61456314, 0.80672   ,\n",
       "        0.69102235],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.13333333, 0.13333333,\n",
       "        0.13333333],\n",
       "       [0.99215686, 1.        , 0.92156863, ..., 0.20482667, 0.37510588,\n",
       "        0.5260749 ],\n",
       "       [0.62489333, 0.62767608, 0.61192941, ..., 0.28783412, 0.3324502 ,\n",
       "        0.28434745]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaled_images = StandardScaler().fit_transform(images)  # scaling the images\n",
    "scaled_images = images\n",
    "scaled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name                                     text_corrected  \\\n",
       "0   image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n",
       "2   image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3   image_4.png              10 Year Challenge - Sweet Dee Edition   \n",
       "4   image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "  overall_sentiment  \n",
       "0     very_positive  \n",
       "1     very_positive  \n",
       "2          positive  \n",
       "3          positive  \n",
       "4           neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labels.csv\", index_col=\"Unnamed: 0\")\n",
    "df = df.drop(columns=[\"text_ocr\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name           0\n",
       "text_corrected       0\n",
       "overall_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(\"\")  # filling nan values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1       4\n",
       "2       2\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "6987    1\n",
       "6988    1\n",
       "6989    2\n",
       "6990    4\n",
       "6991    2\n",
       "Name: overall_sentiment, Length: 6992, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"overall_sentiment\"] = le.fit_transform(df[\"overall_sentiment\"])  # label encoding overall_sentiment\n",
    "df[\"overall_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"image_name\")\n",
    "sorted_overall_sentiment = df[\"overall_sentiment\"][np.argsort(names)]\n",
    "scaled_images = scaled_images[np.argsort(names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = RandomOverSampler().fit_resample(scaled_images, sorted_overall_sentiment)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)  # splitting into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0  # for mean accuracy of all classifiers\n",
    "total_f1 = 0  # for mean f1 score of all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 1 for images\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(x_train, y_train)  # training\n",
    "y_pred = clf.predict(x_test)  # testing\n",
    "acc = accuracy_score(y_pred, y_test)  # accuracy\n",
    "f1 = f1_score(y_pred, y_test, average=\"macro\")  # f1 score\n",
    "total_acc += acc\n",
    "total_f1 += f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6076111288775183\n",
      "f1 score 0.5772317048288638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[574, 112, 116,   0,  60],\n",
       "       [  2, 171, 143,   0, 109],\n",
       "       [ 11, 157, 166,   0,  92],\n",
       "       [  9,  31,  37, 640,  19],\n",
       "       [ 15, 153, 161,   0, 349]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"f1 score\", f1)\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 2 for images\n",
    "clf = DecisionTreeClassifier(splitter=\"best\")\n",
    "clf.fit(x_train, y_train)  # training\n",
    "y_pred = clf.predict(x_test)  # testing\n",
    "acc = accuracy_score(y_pred, y_test)  # accuracy\n",
    "f1 = f1_score(y_pred, y_test, average=\"macro\")  # f1 score\n",
    "total_acc += acc\n",
    "total_f1 += f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7850975375759514\n",
      "f1 score 0.7708562472688787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[602,  30,  56,   0,   7],\n",
       "       [  3, 384, 193,   0,  17],\n",
       "       [  6, 143, 255,   0,  28],\n",
       "       [  0,  10,  17, 640,   3],\n",
       "       [  0,  57, 102,   0, 574]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"f1 score\", f1)\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 3 for images\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)  # training\n",
    "y_pred = clf.predict(x_test)  # testing\n",
    "acc = accuracy_score(y_pred, y_test)  # accuracy\n",
    "f1 = f1_score(y_pred, y_test, average=\"macro\")  # f1 score\n",
    "total_acc += acc\n",
    "total_f1 += f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8343460185481292\n",
      "f1 score 0.8356935025475478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[601,   0,   1,   0,   2],\n",
       "       [  5, 374, 176,   0,  16],\n",
       "       [  2, 239, 429,   0,  46],\n",
       "       [  0,   0,   0, 640,   0],\n",
       "       [  3,  11,  17,   0, 565]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"f1 score\", f1)\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>image_10.png</td>\n",
       "      <td>FACEBOOK '10 YEAR CHALLENGE': A PLOY OR A SIMP...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>image_100.jpg</td>\n",
       "      <td>Drink water you may not meme-generator.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>image_1000.png</td>\n",
       "      <td>RT @BehindScenesPic: Martin Scorsese and Leona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>image_1001.png</td>\n",
       "      <td>Russian Leonardo DiCaprio omg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_name                                     text_corrected  \\\n",
       "0        image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "9       image_10.png  FACEBOOK '10 YEAR CHALLENGE': A PLOY OR A SIMP...   \n",
       "99     image_100.jpg         Drink water you may not meme-generator.com   \n",
       "999   image_1000.png  RT @BehindScenesPic: Martin Scorsese and Leona...   \n",
       "1000  image_1001.png                      Russian Leonardo DiCaprio omg   \n",
       "\n",
       "      overall_sentiment  \n",
       "0                     4  \n",
       "9                     2  \n",
       "99                    1  \n",
       "999                   1  \n",
       "1000                  2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~0123456789'''\n",
    "\n",
    "def text_processing(text):\n",
    "    text = text.lower().strip()  # converting into lowercase\n",
    "    # removing punctuation\n",
    "    for i in text:\n",
    "        if i in punc:\n",
    "            text = text.replace(i, \"\")\n",
    "    text = [a for a in text.split() if a not in stopwords.words('english')]  # removing stopwords\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/b233_h_x6wq9jtl7q88pm0lr0000gn/T/ipykernel_5491/3169551315.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_corrected\"][i] = text_processing(text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       look friend lightyear sohalikut trend play yea...\n",
       "9            moment realize leonardo dicaprio johnny depp\n",
       "99      dr evil literally qualified donald trump far l...\n",
       "999     steve harvey steve harvey stop sending shit ad...\n",
       "1000       tobey maguire leonardo dicaprio take time bowl\n",
       "Name: text_corrected, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, text in enumerate(df[\"text_corrected\"]):\n",
    "    df[\"text_corrected\"][i] = text_processing(text)\n",
    "df[\"text_corrected\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "x_vec = cv.fit_transform(df[\"text_corrected\"])\n",
    "x_vec = x_vec.toarray()\n",
    "x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = RandomOverSampler().fit_resample(x_vec, df[\"overall_sentiment\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)  # splitting into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 1 for text\n",
    "clf = KNeighborsClassifier(n_neighbors=7)\n",
    "clf.fit(x_train, y_train)  # training\n",
    "y_pred = clf.predict(x_test)  # testing\n",
    "acc = accuracy_score(y_pred, y_test)  # accuracy\n",
    "f1 = f1_score(y_pred, y_test, average=\"macro\")  # f1 score\n",
    "total_acc += acc\n",
    "total_f1 += f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.605052766229613\n",
      "f1 score 0.5612087891909721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[576,  98,  86,   0,  41],\n",
       "       [  4, 150, 101,   0,  54],\n",
       "       [  7,  72, 102,   0,  53],\n",
       "       [  1,  36,  36, 639,  38],\n",
       "       [ 23, 289, 296,   0, 425]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"f1 score\", f1)\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 2 for text\n",
    "clf = DecisionTreeClassifier(splitter=\"best\")\n",
    "clf.fit(x_train, y_train)  # training\n",
    "y_pred = clf.predict(x_test)  # testing\n",
    "acc = accuracy_score(y_pred, y_test)  # accuracy\n",
    "f1 = f1_score(y_pred, y_test, average=\"macro\")  # f1 score\n",
    "total_acc += acc\n",
    "total_f1 += f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7556763671250399\n",
      "f1 score 0.7399227083255683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[603,  52,  54,   0,  13],\n",
       "       [  1, 358, 174,   0,  34],\n",
       "       [  0, 136, 247,   0,  32],\n",
       "       [  0,  22,  29, 639,  16],\n",
       "       [  7,  77, 117,   0, 516]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"f1 score\", f1)\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 3 for text\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)  # training\n",
    "y_pred = clf.predict(x_test)  # testing\n",
    "acc = accuracy_score(y_pred, y_test)  # accuracy\n",
    "f1 = f1_score(y_pred, y_test, average=\"macro\")  # f1 score\n",
    "# total_acc += acc\n",
    "# total_f1 += f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7748640869843301\n",
      "f1 score 0.7658217473224319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[600,  33,  34,   0,  15],\n",
       "       [  1, 342, 163,   0,  22],\n",
       "       [  2, 197, 317,   0,  34],\n",
       "       [  0,  21,  19, 639,  15],\n",
       "       [  8,  52,  88,   0, 525]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"f1 score\", f1)\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 0.597963969726042\n",
      "overall f1: 0.580818825360305\n"
     ]
    }
   ],
   "source": [
    "overall_acc = (total_acc / 6)  # overall accuracy\n",
    "overall_f1 = (total_f1 / 6)  # overall f1\n",
    "print(\"overall accuracy:\", overall_acc)\n",
    "print(\"overall f1:\", overall_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
